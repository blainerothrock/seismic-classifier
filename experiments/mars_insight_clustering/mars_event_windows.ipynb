{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Downloading Mars Seismic Data, Splitting Windows\n",
    "This notebook downloads mseed data from IRIS and splits it into 12 second windows sliding by 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "%matplotlib inline\n",
    "\n",
    "import csv, json, os, sys\n",
    "import requests\n",
    "from time import sleep\n",
    "\n",
    "import obspy\n",
    "from obspy import read\n",
    "\n",
    "from obspy.core.event import read_events\n",
    "from obspy import read_inventory\n",
    "from datetime import datetime, timedelta\n",
    "from obspy.core import UTCDateTime\n",
    "\n",
    "\n",
    "DATA_PATH = os.path.expanduser('~/Desktop/seisml-master/testing_ground/mars_insight_seismic/script_tests/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Sample\n",
    "the following:\n",
    "* net=XB\n",
    "* sta=ELYSE\n",
    "* cha=BHU,BHV,BHW\n",
    "* loc=02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data_availability(data_path=DATA_PATH):\n",
    "    try:\n",
    "        os.makedirs(data_path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    payload = {\n",
    "        'option': 'com_ajax',\n",
    "        'data': 'ELYSE',\n",
    "        'format': 'json',\n",
    "        'module': 'seis_data_available'\n",
    "    }\n",
    "    r = requests.post('https://www.seis-insight.eu/en/science/seis-data/seis-data-availability', payload)\n",
    "    with open(os.path.join(data_path, 'data_availability.json'), 'wb') as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'data_availability.json'), 'r') as f:\n",
    "    raw_ava = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ava = []\n",
    "for t in raw_ava['data']:\n",
    "    if t['network'] == 'XB' and t['location'] == '02' and t['channel'] == 'BHU':\n",
    "        ava.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ava[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example data req: `http://ws.ipgp.fr/fdsnws/dataselect/1/query?network=XB&amp;station=ELYSE&amp;startTime=2019-02-12T02:43:01&amp;endTime=2019-02-12T04:14:38&amp;location=02&amp;channel=BH?&amp;nodata=404`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mseed(event, channel='BH?', data_path=DATA_PATH + 'raw/'):\n",
    "    try:\n",
    "        os.makedirs(data_path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    payload = {\n",
    "        'network': event['network'],\n",
    "        'station': event['station'],\n",
    "        'startTime': event['startTime'],\n",
    "        'endTime': event['endTime'],\n",
    "        'location': event['location'],\n",
    "        'channel': channel\n",
    "    }\n",
    "    \n",
    "    req = requests.get('http://ws.ipgp.fr/fdsnws/dataselect/1/query', params=payload)\n",
    "    file_name = '-'.join([event['network'], event['station'], event['location'], event['startTime'], event['endTime']]) + '.mseed'\n",
    "    print('downloading: %s' % file_name)\n",
    "    path = os.path.join(data_path, file_name)\n",
    "    with open(path, 'wb') as c:\n",
    "        c.write(req.content)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download all examples:\n",
    "for event in ava:\n",
    "    download_mseed(event)\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH + 'raw/', 'catelog.json'), 'w') as f:\n",
    "    json.dump(ava, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = list(filter(lambda f: os.path.splitext(f)[1] == '.mseed', os.listdir(DATA_PATH + 'raw/')))\n",
    "print('num of files: %i' % len(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams = []\n",
    "for file in file_names:\n",
    "    streams.append(obspy.read(os.path.join(DATA_PATH + 'raw/', file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As some streams have more than 3 traces (in multiples of 3), we must go through each stream, cut each trace, and rejoin traces to their matching other 2 traces. This is accomplished in the following. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next box is a test for a stream with a small time frame in order to ensure the code works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = []\n",
    "sliced = []\n",
    "for trace in streams[1]:\n",
    "    start = UTCDateTime(trace.stats.starttime)\n",
    "    end = UTCDateTime(trace.stats.endtime)\n",
    "    while start + 12 < end:\n",
    "        sliced.append(trace.slice(start,start+12))\n",
    "        start = start+1.5\n",
    "for aSlice in sliced:\n",
    "    window = []\n",
    "    window.append(aSlice)\n",
    "    sliced.remove(aSlice)\n",
    "    for bSlice in sliced:\n",
    "        if bSlice.stats.starttime == aSlice.stats.starttime:\n",
    "            window.append(bSlice)\n",
    "            sliced.remove(bSlice)\n",
    "    windows.append(obspy.core.Stream(window))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following box is to run for all streams. Takes a VERY long time so be prepared!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = []\n",
    "for stream in streams:\n",
    "    sliced = []\n",
    "    for trace in stream:\n",
    "        start = UTCDateTime(trace.stats.starttime)\n",
    "        end = UTCDateTime(trace.stats.endtime)\n",
    "        while start + 12 < end:\n",
    "            sliced.append(trace.slice(start,start+12))\n",
    "            start = start+3\n",
    "    for aSlice in sliced:\n",
    "        window = []\n",
    "        window.append(aSlice)\n",
    "        sliced.remove(aSlice)\n",
    "        for bSlice in sliced:\n",
    "            if bSlice.stats.starttime == aSlice.stats.starttime:\n",
    "                window.append(bSlice)\n",
    "                sliced.remove(bSlice)\n",
    "        windows.append(obspy.core.Stream(window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obspy",
   "language": "python",
   "name": "obspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
